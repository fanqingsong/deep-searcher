# Milvus å›¾æ–‡æœç´¢å®Œæ•´å®ç°æ•™ç¨‹

## ğŸ¯ é¡¹ç›®æ¦‚è§ˆ

æœ¬æ•™ç¨‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ Milvus å‘é‡æ•°æ®åº“æ„å»ºä¸€ä¸ªå®Œæ•´çš„å›¾æ–‡æœç´¢ç³»ç»Ÿï¼Œæ”¯æŒï¼š
- æ–‡æœ¬æœç´¢å›¾åƒ
- å›¾åƒæœç´¢æ–‡æœ¬  
- å›¾åƒæœç´¢ç›¸ä¼¼å›¾åƒ
- æ¡ä»¶è¿‡æ»¤æœç´¢

## ğŸ“‹ ç¯å¢ƒé…ç½®

### 1. å¯åŠ¨ Milvus æœåŠ¡
```bash
# ä½¿ç”¨ docker-compose å¯åŠ¨
docker-compose up -d

# éªŒè¯æœåŠ¡çŠ¶æ€
docker ps | grep milvus
```

### 2. å®‰è£… Python ä¾èµ–
```bash
pip install pymilvus numpy
# ç”Ÿäº§ç¯å¢ƒè¿˜éœ€è¦ï¼š
pip install transformers torch pillow requests
```

## ğŸ”§ æ ¸å¿ƒå®ç°æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šè¿æ¥æ•°æ®åº“
```python
from pymilvus import MilvusClient
client = MilvusClient("http://localhost:19530")
```

### ç¬¬äºŒæ­¥ï¼šåˆ›å»ºé›†åˆ
```python
collection_name = "multimodal_search"

# åˆ é™¤å·²å­˜åœ¨çš„é›†åˆï¼ˆå¦‚æœ‰ï¼‰
if client.has_collection(collection_name):
    client.drop_collection(collection_name)

# åˆ›å»ºæ–°é›†åˆ
client.create_collection(
    collection_name=collection_name,
    dimension=384,  # å‘é‡ç»´åº¦
    metric_type="COSINE",  # ä½™å¼¦ç›¸ä¼¼åº¦
    consistency_level="Strong"  # å¼ºä¸€è‡´æ€§
)
```

### ç¬¬ä¸‰æ­¥ï¼šå‘é‡åŒ–æ•°æ®
```python
import hashlib
import numpy as np

def text_to_vector(text, dim=384):
    """å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆæ¨¡æ‹Ÿ CLIP ç¼–ç å™¨ï¼‰"""
    # ä½¿ç”¨å“ˆå¸Œç¡®ä¿åŒæ ·æ–‡æœ¬äº§ç”ŸåŒæ ·å‘é‡
    hash_obj = hashlib.md5(text.encode())
    seed = int(hash_obj.hexdigest()[:8], 16)
    np.random.seed(seed)
    
    # ç”Ÿæˆå¹¶å½’ä¸€åŒ–å‘é‡
    vector = np.random.random(dim)
    vector = vector / np.linalg.norm(vector)
    return vector.tolist()

# å®é™…ç”Ÿäº§ä¸­ä½¿ç”¨ CLIP æ¨¡å‹ï¼š
# from transformers import CLIPProcessor, CLIPModel
# model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
# processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
```

### ç¬¬å››æ­¥ï¼šæ’å…¥æ•°æ®
```python
# å‡†å¤‡å¤šæ¨¡æ€æ•°æ®
data = [
    {
        "id": 1, 
        "image_path": "cat_01.jpg",
        "description": "å¯çˆ±çš„æ©™è‰²å°çŒ«åœ¨é˜³å…‰ä¸‹ç©è€",
        "category": "åŠ¨ç‰©",
        "vector": text_to_vector("å¯çˆ±çš„æ©™è‰²å°çŒ«åœ¨é˜³å…‰ä¸‹ç©è€")
    },
    {
        "id": 2,
        "image_path": "dog_02.jpg", 
        "description": "é‡‘æ¯›çŠ¬åœ¨è‰åœ°ä¸Šå¥”è·‘",
        "category": "åŠ¨ç‰©",
        "vector": text_to_vector("é‡‘æ¯›çŠ¬åœ¨è‰åœ°ä¸Šå¥”è·‘")
    },
    # ... æ›´å¤šæ•°æ®
]

# æ‰¹é‡æ’å…¥
client.insert(collection_name, data)

# ç­‰å¾…æ•°æ®å¤„ç†å®Œæˆ
import time
time.sleep(2)
```

### ç¬¬äº”æ­¥ï¼šå®ç°æœç´¢åŠŸèƒ½

#### æ–‡æœ¬æœç´¢å›¾åƒ
```python
def search_images_by_text(query_text, top_k=5):
    """ä½¿ç”¨æ–‡æœ¬æœç´¢ç›¸å…³å›¾åƒ"""
    # å°†æŸ¥è¯¢æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
    query_vector = text_to_vector(query_text)
    
    # æ‰§è¡Œå‘é‡æœç´¢
    results = client.search(
        collection_name=collection_name,
        data=[query_vector],
        limit=top_k,
        output_fields=["image_path", "description", "category"]
    )
    
    return results[0] if results else []

# ä½¿ç”¨ç¤ºä¾‹
results = search_images_by_text("å¯çˆ±çš„å°åŠ¨ç‰©")
for result in results:
    similarity = 1 - result['distance']
    print(f"ç›¸ä¼¼åº¦: {similarity:.3f}")
    print(f"å›¾ç‰‡: {result['entity']['image_path']}")
    print(f"æè¿°: {result['entity']['description']}")
```

#### æ¡ä»¶è¿‡æ»¤æœç´¢
```python
def search_with_filter(query_text, category_filter, top_k=5):
    """å¸¦æ¡ä»¶è¿‡æ»¤çš„æœç´¢"""
    query_vector = text_to_vector(query_text)
    
    results = client.search(
        collection_name=collection_name,
        data=[query_vector],
        limit=top_k,
        filter=f'category == "{category_filter}"',  # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        output_fields=["image_path", "description", "category"]
    )
    
    return results[0] if results else []

# åªæœç´¢åŠ¨ç‰©ç±»åˆ«
animal_results = search_with_filter("æ¯›èŒ¸èŒ¸çš„", "åŠ¨ç‰©")
```

## ğŸš€ è¿è¡Œæ¼”ç¤º

æˆ‘ä»¬æä¾›äº†å‡ ä¸ªç¤ºä¾‹æ–‡ä»¶ï¼š

### 1. åŸºç¡€ç¤ºä¾‹
```bash
python3 simple_example.py
```
å±•ç¤ºåŸºæœ¬çš„å‘é‡æœç´¢åŸç†å’Œæ“ä½œã€‚

### 2. æœç´¢æ¼”ç¤º  
```bash
python3 demo_search.py
```
æ¼”ç¤ºæ–‡æœ¬åˆ°æ–‡æœ¬çš„ç›¸ä¼¼æ€§æœç´¢ã€‚

## ğŸ“Š å®é™…åº”ç”¨åœºæ™¯

### 1. ç”µå•†å¹³å°
```python
# ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æœç´¢ç›¸ä¼¼å•†å“
user_image = "user_upload.jpg"
similar_products = search_images_by_image(user_image, top_k=10)

# ç”¨æˆ·è¾“å…¥æè¿°æœç´¢å•†å“
query = "çº¢è‰²è¿è¡£è£™"
products = search_images_by_text(query, top_k=10)
```

### 2. å†…å®¹ç®¡ç†ç³»ç»Ÿ
```python
# ç¼–è¾‘æ ¹æ®æ–‡ç« å†…å®¹æœç´¢é…å›¾
article_content = "ç§‘æŠ€åˆ›æ–°æ”¹å˜ç”Ÿæ´»"
relevant_images = search_images_by_text(article_content, top_k=5)

# æ ¹æ®ç°æœ‰å›¾ç‰‡æ‰¾ç›¸ä¼¼ç´ æ
reference_image = "tech_innovation.jpg"
similar_images = search_images_by_image(reference_image, top_k=8)
```

### 3. æ™ºèƒ½ç›¸å†Œ
```python
# è¯­ä¹‰æœç´¢ä¸ªäººç…§ç‰‡
search_results = search_images_by_text("ç”Ÿæ—¥èšä¼š")
search_results = search_images_by_text("æµ·è¾¹åº¦å‡")
search_results = search_images_by_text("å® ç‰©ç…§ç‰‡")
```

## ğŸ›ï¸ æ€§èƒ½ä¼˜åŒ–

### 1. ç´¢å¼•ä¼˜åŒ–
```python
# åˆ›å»ºé«˜æ€§èƒ½ç´¢å¼•
index_params = {
    "index_type": "HNSW",
    "metric_type": "COSINE", 
    "params": {"M": 16, "efConstruction": 200}
}

client.create_index(
    collection_name=collection_name,
    field_name="vector",
    index_params=index_params
)
```

### 2. æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡æ’å…¥ä¼˜åŒ–
batch_size = 1000
for i in range(0, len(large_dataset), batch_size):
    batch = large_dataset[i:i + batch_size]
    client.insert(collection_name, batch)
    
    # å®šæœŸåˆ·æ–°
    if i % (batch_size * 10) == 0:
        client.flush(collection_name)
```

### 3. å†…å­˜ç®¡ç†
```python
# åŠ è½½é›†åˆåˆ°å†…å­˜ä»¥æå‡æœç´¢é€Ÿåº¦
client.load_collection(collection_name)

# ä¸ä½¿ç”¨æ—¶é‡Šæ”¾å†…å­˜
client.release_collection(collection_name)
```

## ğŸ“ˆ æ‰©å±•åŠŸèƒ½

### 1. æ··åˆæœç´¢
```python
def hybrid_search(text_query, image_query=None, weights=[0.7, 0.3]):
    """ç»“åˆæ–‡æœ¬å’Œå›¾åƒçš„æ··åˆæœç´¢"""
    text_results = search_images_by_text(text_query, top_k=20)
    
    if image_query:
        image_results = search_images_by_image(image_query, top_k=20)
        # å®ç°ç»“æœèåˆé€»è¾‘
        return merge_results(text_results, image_results, weights)
    else:
        return text_results[:10]
```

### 2. å®æ—¶æ›´æ–°
```python
def update_data(item_id, new_description, new_image_path):
    """å®æ—¶æ›´æ–°æ•°æ®"""
    # åˆ é™¤æ—§æ•°æ®
    client.delete(collection_name, expr=f"id == {item_id}")
    
    # æ’å…¥æ–°æ•°æ®
    new_vector = text_to_vector(new_description)
    new_data = [{
        "id": item_id,
        "image_path": new_image_path,
        "description": new_description,
        "vector": new_vector
    }]
    client.insert(collection_name, new_data)
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **è¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥æœåŠ¡çŠ¶æ€
   docker ps | grep milvus
   # é‡å¯æœåŠ¡
   docker-compose restart
   ```

2. **æœç´¢æ— ç»“æœ**
   ```python
   # ç¡®ä¿æ•°æ®å·²æ’å…¥
   client.flush(collection_name)
   # æ£€æŸ¥é›†åˆçŠ¶æ€
   client.get_collection_stats(collection_name)
   ```

3. **æ€§èƒ½è¾ƒæ…¢**
   ```python
   # æ£€æŸ¥æ˜¯å¦å·²åˆ›å»ºç´¢å¼•
   client.list_indexes(collection_name)
   # æ£€æŸ¥é›†åˆæ˜¯å¦å·²åŠ è½½
   client.get_load_state(collection_name)
   ```

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å‘é‡è´¨é‡**: ä½¿ç”¨é«˜è´¨é‡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆCLIP, BERTç­‰ï¼‰
2. **æ•°æ®é¢„å¤„ç†**: æ¸…æ´—å’Œæ ‡å‡†åŒ–è¾“å…¥æ•°æ®
3. **ç´¢å¼•é€‰æ‹©**: æ ¹æ®æ•°æ®è§„æ¨¡é€‰æ‹©åˆé€‚çš„ç´¢å¼•ç±»å‹
4. **æ‰¹é‡æ“ä½œ**: å¤§æ•°æ®é‡æ—¶ä½¿ç”¨æ‰¹é‡æ’å…¥å’Œæœç´¢
5. **ç›‘æ§ç»´æŠ¤**: å®šæœŸç›‘æ§æ€§èƒ½å’Œå­˜å‚¨ä½¿ç”¨æƒ…å†µ

## ğŸ”— å‚è€ƒèµ„æº

- [Milvus å®˜æ–¹æ–‡æ¡£](https://milvus.io/docs)
- [CLIP æ¨¡å‹ä»‹ç»](https://github.com/openai/CLIP)
- [PyMilvus API å‚è€ƒ](https://milvus.io/api-reference/pymilvus)
- [å‘é‡æ•°æ®åº“æœ€ä½³å®è·µ](https://zilliz.com/learn)

---

é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å·²ç»æŒæ¡äº†ä½¿ç”¨ Milvus æ„å»ºå›¾æ–‡æœç´¢ç³»ç»Ÿçš„å®Œæ•´æµç¨‹ã€‚ç°åœ¨å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚æ‰©å±•å’Œä¼˜åŒ–æ‚¨çš„å¤šæ¨¡æ€æœç´¢åº”ç”¨ï¼

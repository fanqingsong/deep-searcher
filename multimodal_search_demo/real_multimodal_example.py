#!/usr/bin/env python3
"""
çœŸå®çš„å›¾æ–‡æœç´¢ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•å®ç°æ–‡æœ¬æœç´¢å›¾åƒå’Œå›¾åƒæœç´¢æ–‡æœ¬
"""

from pymilvus import MilvusClient
import numpy as np
import hashlib

def text_to_vector(text, dim=512):
    """æ¨¡æ‹ŸCLIPæ–‡æœ¬ç¼–ç å™¨"""
    hash_obj = hashlib.md5(text.encode())
    seed = int(hash_obj.hexdigest()[:8], 16)
    np.random.seed(seed)
    
    vector = np.random.random(dim)
    vector = vector / np.linalg.norm(vector)
    
    # æ·»åŠ è¯­ä¹‰ç›¸å…³æ€§
    keywords = {
        "çŒ«": [0.8, 0.2, 0.1], "ç‹—": [0.7, 0.3, 0.15], "åŠ¨ç‰©": [0.75, 0.25, 0.12],
        "é£æ™¯": [0.1, 0.8, 0.3], "å±±": [0.05, 0.85, 0.35], "æ¹–": [0.08, 0.82, 0.32],
        "å»ºç­‘": [0.2, 0.1, 0.8], "åŸå¸‚": [0.25, 0.15, 0.75],
        "èŠ±": [0.3, 0.6, 0.2], "æ¤ç‰©": [0.35, 0.65, 0.25]
    }
    
    for keyword, weights in keywords.items():
        if keyword in text:
            vector[:3] = np.array(weights)
            break
    
    return vector.tolist()

def main():
    print("ğŸš€ çœŸå®å›¾æ–‡æœç´¢ç³»ç»Ÿæ¼”ç¤º")
    
    client = MilvusClient("http://localhost:19530")
    collection_name = "multimodal_demo"
    
    # åˆ›å»ºé›†åˆ
    if client.has_collection(collection_name):
        client.drop_collection(collection_name)
    
    client.create_collection(
        collection_name=collection_name,
        dimension=512,
        metric_type="COSINE"
    )
    
    # ç¤ºä¾‹æ•°æ®
    dataset = [
        {"id": 1, "image_path": "cat_01.jpg", "description": "ä¸€åªæ©™è‰²å°çŒ«åœ¨é˜³å…‰ä¸‹ç©è€", "category": "åŠ¨ç‰©"},
        {"id": 2, "image_path": "dog_02.jpg", "description": "é‡‘æ¯›çŠ¬åœ¨å…¬å›­è‰åœ°ä¸Šå¥”è·‘", "category": "åŠ¨ç‰©"},
        {"id": 3, "image_path": "mountain_03.jpg", "description": "æ¸…æ™¨çš„é«˜å±±æ¹–æ³Šå€’æ˜ é›ªå±±", "category": "é£æ™¯"},
        {"id": 4, "image_path": "city_04.jpg", "description": "ç°ä»£åŒ–åŸå¸‚å¤©é™…çº¿", "category": "å»ºç­‘"},
        {"id": 5, "image_path": "flower_05.jpg", "description": "æ˜¥å¤©èŠ±å›­é‡Œç››å¼€çš„èŠ±æœµ", "category": "æ¤ç‰©"}
    ]
    
    # ç”Ÿæˆå‘é‡å¹¶æ’å…¥
    data = []
    for item in dataset:
        vector = text_to_vector(item["description"])
        data.append({
            "id": item["id"],
            "image_path": item["image_path"],
            "description": item["description"], 
            "category": item["category"],
            "vector": vector
        })
    
    client.insert(collection_name, data)
    
    # æ–‡æœ¬æœç´¢æ¼”ç¤º
    print("\nğŸ“ æ–‡æœ¬æœç´¢å›¾åƒæ¼”ç¤º:")
    queries = ["å¯çˆ±çš„å°çŒ«", "è‡ªç„¶é£æ™¯", "ç°ä»£å»ºç­‘"]
    
    for query in queries:
        print(f"\nğŸ” æœç´¢: '{query}'")
        query_vector = text_to_vector(query)
        
        results = client.search(
            collection_name=collection_name,
            data=[query_vector],
            limit=3,
            output_fields=["image_path", "description", "category"]
        )
        
        for i, result in enumerate(results[0], 1):
            similarity = 1 - result['distance']
            entity = result['entity']
            print(f"  {i}. ç›¸ä¼¼åº¦: {similarity:.3f}")
            print(f"     å›¾ç‰‡: {entity['image_path']}")
            print(f"     æè¿°: {entity['description']}")
    
    print("\nâœ… æ¼”ç¤ºå®Œæˆ!")
    client.drop_collection(collection_name)

if __name__ == "__main__":
    main()

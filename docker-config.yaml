provide_settings:
  llm:
    provider: "SiliconFlow"
    config:
      model: "deepseek-ai/DeepSeek-V3"

  embedding:
    provider: "SiliconflowEmbedding"
    config:
      model: "BAAI/bge-m3"

  file_loader:
    provider: "PDFLoader"
    config: {}

  web_crawler:
    provider: "FireCrawlCrawler"
    config: {}

  vector_db:
    provider: "Milvus"
    config:
      default_collection: "deepsearcher"
      uri: "http://milvus:19530"  # Docker service name
      token: "root:Milvus"
      db: "default"

query_settings:
  max_iter: 3

load_settings:
  chunk_size: 1500
  chunk_overlap: 100 